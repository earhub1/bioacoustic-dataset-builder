"""CLI to visualize synthetic sequences produced by build_dataset.py.

The tool rebuilds an approximate waveform timeline for each sequence using the
original audio segments referenced in the fragment manifests, then renders a
4-row plot with waveform, spectrogram, stored MFCCs, and a binary mask
(Nothing vs. outras classes).
"""
from __future__ import annotations

import argparse
import json
import logging
from pathlib import Path
from typing import Dict, List, Optional, Sequence

import librosa
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

logger = logging.getLogger(__name__)

DEFAULT_SEQUENCE_MANIFEST = Path("data/results/sequences/manifest_sequences.csv")
DEFAULT_FRAGMENTS_DIR = Path("data/results/fragments")
DEFAULT_OUTPUT_DIR = Path("data/results/sequence_viz")


def parse_args(args: Optional[Sequence[str]] = None) -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Visualize synthetic sequences with waveform, spectrogram, MFCCs, and mask.")
    parser.add_argument(
        "--sequence-manifest",
        type=Path,
        default=DEFAULT_SEQUENCE_MANIFEST,
        help="Path to manifest_sequences.csv generated by build_dataset.py.",
    )
    parser.add_argument(
        "--fragments-dir",
        action="append",
        type=Path,
        default=None,
        help=(
            "Directory containing fragment outputs and manifest.csv. Can be passed multiple times; "
            "defaults to data/results/fragments."
        ),
    )
    parser.add_argument(
        "--output-dir",
        type=Path,
        default=DEFAULT_OUTPUT_DIR,
        help="Where to save the visualization PNGs.",
    )
    parser.add_argument(
        "--splits",
        nargs="+",
        default=None,
        help="Optional list of splits to visualize (e.g., train val test).",
    )
    parser.add_argument(
        "--max-sequences",
        type=int,
        default=None,
        help="Maximum number of sequences to render (after filters).",
    )
    parser.add_argument(
        "--frame-length",
        type=int,
        default=6400,
        help="Frame length in samples used when converting frames to seconds/samples.",
    )
    parser.add_argument(
        "--hop-length",
        type=int,
        default=6400,
        help="Hop length in samples used when converting frames to seconds/samples.",
    )
    parser.add_argument(
        "--target-sr",
        type=int,
        default=64000,
        help="Sampling rate used for waveform reconstruction and duration calculations.",
    )
    parser.add_argument(
        "--n-fft",
        type=int,
        default=1024,
        help="FFT size for the spectrogram plot.",
    )
    parser.add_argument(
        "--spectrogram-hop-length",
        type=int,
        default=512,
        help="Hop length for the spectrogram plot.",
    )
    return parser.parse_args(args=args)


def frames_to_samples(n_frames: int, frame_length: int, hop_length: int) -> int:
    if n_frames <= 0:
        return 0
    if n_frames == 1:
        return frame_length
    return int((n_frames - 1) * hop_length + frame_length)


def frames_to_seconds(n_frames: int, sr: int, frame_length: int, hop_length: int) -> float:
    if n_frames <= 0:
        return 0.0
    return ((n_frames - 1) * hop_length + frame_length) / float(sr)


def resolve_sequence_path(sequence_path: str, manifest_dir: Path) -> Path:
    path = Path(sequence_path)
    if path.is_absolute() or ":" in sequence_path:
        return path
    if path.exists():
        return path
    return manifest_dir / path


def load_fragment_metadata(fragment_dirs: List[Path]) -> Dict[str, dict]:
    mapping: Dict[str, dict] = {}
    for frag_dir in fragment_dirs:
        manifest_path = frag_dir / "manifest.csv"
        if not manifest_path.exists():
            logger.warning("Skipping %s because manifest.csv is missing", manifest_path)
            continue
        df = pd.read_csv(manifest_path)
        for _, row in df.iterrows():
            snippet_path = Path(row["snippet_path"])
            if not snippet_path.is_absolute():
                snippet_path = manifest_path.parent / snippet_path
            mapping[str(snippet_path)] = row.to_dict()
    if not mapping:
        raise FileNotFoundError("No fragment metadata found; ensure manifest.csv files exist in --fragments-dir.")
    return mapping


def reconstruct_waveform(
    segments: List[dict],
    total_frames: int,
    meta_map: Dict[str, dict],
    sr: int,
    frame_length: int,
    hop_length: int,
) -> np.ndarray:
    total_samples = frames_to_samples(total_frames, frame_length, hop_length)
    waveform = np.zeros(total_samples, dtype=np.float32)

    for seg in segments:
        snippet_meta = meta_map.get(seg["snippet_path"])
        if snippet_meta is None:
            logger.warning("Metadata not found for snippet %s; skipping", seg["snippet_path"])
            continue

        source = snippet_meta.get("source_filepath") or snippet_meta.get("filepath")
        onset = float(snippet_meta.get("onset_s", 0.0))
        offset = float(snippet_meta.get("offset_s", onset))
        duration = max(offset - onset, 0.0)
        if not source or duration <= 0:
            logger.warning("Invalid source or duration for %s; skipping", seg["snippet_path"])
            continue

        try:
            audio, _ = librosa.load(source, sr=sr, mono=True, offset=onset, duration=duration)
        except Exception as exc:  # noqa: BLE001
            logger.warning("Failed to load %s: %s", source, exc)
            continue

        start_sample = int(seg["start_frame"] * hop_length)
        end_sample = min(start_sample + len(audio), len(waveform))
        if start_sample >= len(waveform):
            continue
        waveform[start_sample:end_sample] += audio[: end_sample - start_sample]

    return waveform


def plot_sequence(
    sequence_record: pd.Series,
    meta_map: Dict[str, dict],
    output_dir: Path,
    manifest_dir: Path,
    sr: int,
    frame_length: int,
    hop_length: int,
    n_fft: int,
    spectrogram_hop_length: int,
) -> Path:
    segments = json.loads(sequence_record["segments"])
    total_frames = int(sequence_record["total_frames"])
    sequence_path = resolve_sequence_path(str(sequence_record["sequence_path"]), manifest_dir)

    waveform = reconstruct_waveform(
        segments=segments,
        total_frames=total_frames,
        meta_map=meta_map,
        sr=sr,
        frame_length=frame_length,
        hop_length=hop_length,
    )

    # Compute spectrogram for visualization.
    spec = np.abs(librosa.stft(waveform, n_fft=n_fft, hop_length=spectrogram_hop_length))
    spec_db = librosa.amplitude_to_db(spec + 1e-9, ref=np.max)

    # Load stored MFCCs for the assembled sequence.
    mfcc = np.load(sequence_path)

    # Binary mask (frames) for Nothing vs outras classes.
    mask = np.zeros(total_frames, dtype=int)
    for seg in segments:
        start = int(seg["start_frame"])
        end = int(seg["end_frame"])
        value = 0 if seg["label"] == "Nothing" else 1
        mask[start:end] = value

    time_wave = np.arange(len(waveform)) / float(sr)
    time_mask = np.arange(total_frames) * (hop_length / float(sr))

    output_dir.mkdir(parents=True, exist_ok=True)
    fig, axes = plt.subplots(4, 1, figsize=(12, 10), sharex=False)

    axes[0].plot(time_wave, waveform)
    axes[0].set_title("Waveform timeline")
    axes[0].set_ylabel("Amplitude")

    img = axes[1].imshow(
        spec_db,
        origin="lower",
        aspect="auto",
        extent=[time_wave[0] if len(time_wave) else 0, time_wave[-1] if len(time_wave) else 0, 0, sr / 2],
        cmap="magma",
    )
    axes[1].set_title("Spectrogram (dB)")
    axes[1].set_ylabel("Frequency (Hz)")
    fig.colorbar(img, ax=axes[1], format="%.0f dB")

    axes[2].imshow(mfcc, origin="lower", aspect="auto", cmap="viridis")
    axes[2].set_title("Stored MFCC sequence")
    axes[2].set_ylabel("Coeff")

    axes[3].step(time_mask, mask, where="post")
    axes[3].set_title("Binary mask (1 = evento, 0 = Nothing)")
    axes[3].set_xlabel("Time (s)")
    axes[3].set_ylabel("Mask")
    axes[3].set_ylim(-0.1, 1.1)

    fig.tight_layout()
    out_path = output_dir / f"{sequence_path.stem}.png"
    fig.savefig(out_path, dpi=200)
    plt.close(fig)
    return out_path


def main(cli_args: Optional[Sequence[str]] = None) -> None:
    args = parse_args(cli_args)
    logging.basicConfig(level=logging.INFO, format="[%(levelname)s] %(message)s")

    fragments_dirs = args.fragments_dir or [DEFAULT_FRAGMENTS_DIR]
    meta_map = load_fragment_metadata(fragments_dirs)

    seq_manifest = pd.read_csv(args.sequence_manifest)
    if args.splits:
        seq_manifest = seq_manifest[seq_manifest["split"].isin(args.splits)]

    if seq_manifest.empty:
        raise ValueError("No sequences found after applying split filters.")

    if args.max_sequences is not None:
        seq_manifest = seq_manifest.head(args.max_sequences)

    output_dir = args.output_dir
    output_dir.mkdir(parents=True, exist_ok=True)
    manifest_dir = args.sequence_manifest.parent

    for _, row in seq_manifest.iterrows():
        out_path = plot_sequence(
            sequence_record=row,
            meta_map=meta_map,
            output_dir=output_dir,
            manifest_dir=manifest_dir,
            sr=args.target_sr,
            frame_length=args.frame_length,
            hop_length=args.hop_length,
            n_fft=args.n_fft,
            spectrogram_hop_length=args.spectrogram_hop_length,
        )
        logger.info("Saved visualization to %s", out_path)


if __name__ == "__main__":
    main()
